# SMGeo
This repository is the official implementation of ArXiv "SMGeo: Cross-View Object Geo-Localization with Grid-Level Mixture-of-Experts"
## ðŸ“Œ Abstract

Cross-view object geo-localization aims to precisely pinpoint the same object across large-scale satellite imagery based on drone images. Due to significant differences in viewpoint and scale, coupled with complex background interference, traditional multi-stage *retrievalâ€“matching* pipelines are prone to cumulative errors. To address these challenges, we present **SMGeo**, a promptable end-to-end transformer-based model for object geo-localization. The proposed model supports **click-based prompting** and can output object geo-localization results **in real time**, enabling interactive use. SMGeo adopts a fully transformer-based architecture, utilizing a **Swin Transformer** for joint feature encoding of both drone and satellite imagery, together with an **anchor-free transformer detection head** for direct coordinate regression. To better capture both **inter-view** and **intra-view** dependencies, we further introduce a **grid-level sparse Mixture-of-Experts (GMoE)** module into the cross-view encoder. This design allows the network to adaptively activate specialized experts according to the **content, scale, and source** of each spatial grid. In addition, the anchor-free detection head predicts object locations via **heatmap-based supervision** on reference images, avoiding the scale bias and matching complexity introduced by predefined anchor boxes.
---

## ðŸ›  Preparation

### 1. Dataset

We use the **CVOGL** dataset for cross-view object geo-localization experiments.

- **CVOGL Dataset**:  
  [Google Drive Download](https://drive.google.com/file/d/1WCwnK_rrU--ZOIQtmaKdR0TXcmtzU4cf/view)

Please download the dataset and organize it under the `data/` directory.

---

### 2. Backbone Pretrained Weights

SMGeo adopts **Swin Transformer** as the backbone network.

- **Official Swin Transformer Repository**:  
  [https://github.com/microsoft/Swin-Transformer](https://github.com/microsoft/Swin-Transformer)

---

### 3. Provided Model Weights

We provide:
- A **Swin-Tiny pretrained model**
- A **SMGeo model trained for X epochs**

These files are shared via Baidu Netdisk:

- **SMGeo Model Weights**  
  Link: https://pan.baidu.com/s/1aq_VjzaGtX5-qIUmCi0zIg  
  Password: `vykd`

Please download and place the weights in the designated checkpoint directory before training or inference.

---

## ðŸš€ Training, Testing and Inference

### Training Script

The main training script is:

```bash
python enhanced_training.py \
  --data_root "data" \
  --data_name "CVOGL_DroneAerial" \
  --gpu "0,1,2" \
  --savename "optimized_enhanced_25epoch" \
  --max_epoch 25 \
  --batch_size 8 \
  --img_size 1024 \
  --cosine
```
### Visualization and Inference

For visualization and inference, use:
```bash
visualization_core.py
```
---

## ðŸ“Š Results and Visualization

### 1. Quantitative Results

We evaluate SMGeo on the **CVOGL_DroneAerial** benchmark and compare it with several representative cross-view geo-localization methods.  
The performance is reported in terms of **acc@0.25**, **acc@0.5**, and **mIoU** on both the test and validation sets.

> SMGeo consistently outperforms previous methods by a large margin, demonstrating the effectiveness of grid-level Mixture-of-Experts modeling for cross-view object geo-localization.

<img width="452" height="268" alt="image" src="https://github.com/user-attachments/assets/6d910729-ccea-4855-b56d-a69cb0404ed2" />


---

### 2. Qualitative Comparison with State-of-the-Art Methods

We visualize object geo-localization results produced by different methods, including **TransGeo**, **DSTG**, and **SMGeo**.

- **Red box**: ground-truth object location  
- **Colored boxes**: predicted localization results  
- **Star marker**: query object

SMGeo yields significantly more accurate localization results, especially in complex urban scenes with severe background clutter and scale variation.

<img width="1997" height="2048" alt="image" src="https://github.com/user-attachments/assets/045bbed9-8ade-4cca-a9cb-6b0301246704" />


---

### 3. Cross-View Localization Results (Drone â†’ Satellite)

We further present qualitative results on drone-to-satellite geo-localization across different object scales.

- **First row**: query images captured from drones  
- **Second row**: satellite reference images  
- **Third row**: localization results produced by SMGeo  

The results are grouped into **small**, **medium**, and **large** target scenarios, showing that SMGeo maintains robust performance across varying object scales.

<img width="933" height="492" alt="image" src="https://github.com/user-attachments/assets/4c29adc0-37ea-430f-b0b0-cf2d7f0e12e7" />


---

### 4. Response Heatmap Visualization

To better understand the modelâ€™s localization behavior, we visualize the **response heatmaps** generated by SMGeo.

- The heatmaps highlight regions with high confidence responses
- Accurate localization corresponds to concentrated and well-aligned activation regions

These visualizations indicate that SMGeo effectively suppresses background noise while focusing on the true object location.

<img width="1962" height="2048" alt="image" src="https://github.com/user-attachments/assets/1104de59-7ff6-4a6a-8935-fb4ae4c7a9fd" />


---

### 5. Inference Speed and Video Results

We provide inference videos demonstrating the real-time capability of SMGeo.

- **Average inference time**: ~0.17 seconds per image

The inference videos can be downloaded from the following link:

- Link: https://pan.baidu.com/s/1aq_VjzaGtX5-qIUmCi0zIg  
- Password: `vykd`

---

### 6. Expert Activation Visualization (Ablation Analysis)

To analyze the behavior of the grid-level Mixture-of-Experts module, we visualize the **expert activation maps** at different encoder stages.

- Each grid cell is assigned a color indicating its activated expert
- Different stages exhibit distinct expert specialization patterns

The visualization script is provided as:

```bash
expert_activation_visualization.py

```




